Module path:  Environments.Gridworld_SAS Gridworld_SAS
Dynamically loaded from:  <class 'Environments.Gridworld_SAS.Gridworld_SAS'>
difficulty 1
Module path:  Src.Algorithms.Stochastic_Actions.SAS_PGQV SAS_PGQV
Dynamically loaded from:  <class 'Src.Algorithms.Stochastic_Actions.SAS_PGQV.SAS_PGQV'>
=====Configurations=====
 Namespace(NN_basis_dim='256', Policy_basis_dim='2,16', SAS_q_updates=16, SF_bridge_prob=-1, action_prob=0.2, actor_lr=0.0001, algo_name='SAS_PGQV', alpha_rate=0.9999, base=-2, batch_size=16, buffer_size=10000, debug=False, difficulty=1, env_name='Gridworld_SAS', exp=0.075, experiment='Test_run', folder_suffix='p_02', fourier_coupled=True, fourier_order=3, gamma=0.99, gpu=0, hyper=-2, inc=-2, log_output='term_file', max_episodes=20000, max_steps=150, n_actions=16, optim='sgd', q_lr=0.001, restore=False, save_count=19999, save_model=True, seed=17, state_lr=0.001, summary=True, timestamp='5|22|22:9:40', trace_lambda=0.9, v_lr=0.01)
Actions space: 16 :: State space: 2
0 :: Rewards -0.039 :: steps: 80.00 :: Time: 0.024(0.00030/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.50003726 -0.49997527]
1000 :: Rewards 8.050 :: steps: 76.00 :: Time: 0.016(0.00021/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.44973281 -0.54367935]
2000 :: Rewards 49.870 :: steps: 80.00 :: Time: 0.016(0.00020/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.40452443 -0.60442601]
3000 :: Rewards 83.096 :: steps: 58.00 :: Time: 0.016(0.00028/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.38585507 -0.64019329]
4000 :: Rewards 84.959 :: steps: 40.00 :: Time: 0.016(0.00039/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.37253107 -0.65843088]
5000 :: Rewards 90.843 :: steps: 51.00 :: Time: 0.029(0.00057/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.36459835 -0.67016506]
6000 :: Rewards 92.798 :: steps: 42.00 :: Time: 0.016(0.00037/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.35973799 -0.67661643]
7000 :: Rewards 93.845 :: steps: 73.00 :: Time: 0.000(0.00000/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.35185507 -0.68602243]
8000 :: Rewards 96.254 :: steps: 54.00 :: Time: 0.020(0.00037/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.34072871 -0.69885131]
9000 :: Rewards 94.208 :: steps: 26.00 :: Time: 0.016(0.00060/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.33995379 -0.69910405]
10000 :: Rewards 95.103 :: steps: 19.00 :: Time: 0.000(0.00000/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.32733076 -0.71223964]
11000 :: Rewards 95.953 :: steps: 19.00 :: Time: 0.000(0.00000/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.31775716 -0.722387  ]
12000 :: Rewards 97.116 :: steps: 21.00 :: Time: 0.000(0.00000/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.30765086 -0.73300115]
13000 :: Rewards 97.131 :: steps: 44.00 :: Time: 0.022(0.00050/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.30738562 -0.73267452]
14000 :: Rewards 97.345 :: steps: 10.00 :: Time: 0.016(0.00156/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.3022223  -0.73740651]
15000 :: Rewards 97.192 :: steps: 16.00 :: Time: 0.000(0.00000/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.29592538 -0.74360579]
16000 :: Rewards 96.888 :: steps: 33.00 :: Time: 0.000(0.00000/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.2946456  -0.74384572]
17000 :: Rewards 96.791 :: steps: 36.00 :: Time: 0.008(0.00022/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.28800842 -0.75042595]
18000 :: Rewards 97.886 :: steps: 29.00 :: Time: 0.016(0.00054/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.28388558 -0.75469421]
19000 :: Rewards 97.184 :: steps: 33.00 :: Time: 0.010(0.00031/step) :: Entropy : 0.000 :: Grads : [] :: Alpha : [-0.28050327 -0.75749411]
579.7189633846283
